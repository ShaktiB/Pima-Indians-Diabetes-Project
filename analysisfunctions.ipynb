{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'modeleval' function returns all the evaluation metrics that are being used to gage all the model's performance\n",
    "\n",
    "def modeleval(yTrue, yPredict, print_metrics):\n",
    "    # Area Under ROC Curve\n",
    "    auc = roc_auc_score(yTrue,yPredict)\n",
    "\n",
    "    # Confusion Matrix Evaluation \n",
    "    cm = confusion_matrix(yTrue,yPredict)\n",
    "\n",
    "    # True negative, Flase positive, false negative, true positive\n",
    "    tn, fp, fn, tp = confusion_matrix(yTrue,yPredict).ravel() \n",
    "\n",
    "    # True Positive Rate (Sensitivity)\n",
    "    tpr = tp/(tp+fn)\n",
    "\n",
    "    # True Negative Rate (Specificity)\n",
    "    tnr = tn/(tn+fp)\n",
    "\n",
    "    # Accuracy \n",
    "    acc = accuracy_score(yTrue,yPredict)\n",
    "    \n",
    "    # Model Metrics\n",
    "    mm = {\n",
    "        'AUC':auc,\n",
    "        'Confusion Matrix':cm,\n",
    "        'TN':tn,\n",
    "        'FP':fp,\n",
    "        'FN':fn,\n",
    "        'TP':tp,\n",
    "        'TPR':tpr,\n",
    "        'TNR':tnr,\n",
    "        'Accuracy':acc\n",
    "    }\n",
    "    \n",
    "    if print_metrics:\n",
    "        print(f\"Sensitivity:{mm['TPR']}\\n\\n\\\n",
    "Specificity:{mm['TNR']}\\n\\n\\\n",
    "AUC of ROC:{mm['AUC']}\\n\\n\\\n",
    "Accuracy:{mm['Accuracy']}\\n\\n\")\n",
    "        \n",
    "        x = pd.crosstab(yTrue, yPredict, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "        print(f\"{x}\\n\")\n",
    "        plot_confusion_matrix(yTrue, yPredict,classes=np.array(['No Diabetes','Diabetes']),\n",
    "                      title='Confusion matrix: SVM')\n",
    "        plt.show()\n",
    "    \n",
    "    return mm       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotroc(yvt,yvp,modelname): # y_validation_truth & y_validation_prediction\n",
    "    f, t, thresh = roc_curve(yvt, yvp)\n",
    "    roc_auc = auc(f, t)\n",
    "    plt.title('Receiver Operating Characteristic: ' + modelname)\n",
    "    plt.plot(f, t, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e8bc49331c40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                           \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                           \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                           cmap=plt.cm.Blues):\n\u001b[0m\u001b[0;32m      7\u001b[0m     \"\"\"\n\u001b[0;32m      8\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mprints\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mplots\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconfusion\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot Confusion Matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    \"\"\"if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm) \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "# This function was obtained from the Scikit-learn documentation for plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
